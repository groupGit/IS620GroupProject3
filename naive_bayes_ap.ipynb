{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS620 Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Group project: Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev- test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= blue> <b>Group Members:- Aaron Palumbo, Brian Chu,  David Stern, Partha Banerjee;  Rohan Fray, Tulasi Ramarao;</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import networkx as nx\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7332"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load qtutil.py\n",
    "# silly utility to launch a qtconsole if one doesn't exist\n",
    "import psutil\n",
    "\n",
    "def returnPyIDs():\n",
    "    pyids = set()\n",
    "    for pid in psutil.pids():\n",
    "        try:\n",
    "            if \"python\" in psutil.Process(pid).name():\n",
    "                pyids.add(pid)\n",
    "        except:\n",
    "            pass\n",
    "    return pyids\n",
    "\n",
    "def launchConsole():\n",
    "    before_pyids = returnPyIDs()\n",
    "    %qtconsole\n",
    "    after_pyids = returnPyIDs()\n",
    "    newid = after_pyids.difference(before_pyids)\n",
    "    assert len(newid) == 1\n",
    "    return list(newid)[0]\n",
    "\n",
    "try:\n",
    "    qtid\n",
    "except NameError:\n",
    "    qtid = launchConsole()\n",
    "    \n",
    "if qtid not in returnPyIDs():\n",
    "    qtid = launchConsole()\n",
    "    \n",
    "qtid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = nltk.corpus.names\n",
    "maleNames = names.words('male.txt')\n",
    "femaleNames = names.words('female.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training Data\n",
    "\n",
    "    * Train Set: Used to train the model\n",
    "\n",
    "    * Validation Set: Model Selection\n",
    "\n",
    "* Test Set: Measure Final Model performance (Only use this once at the end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different numbers of male and female names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of male names: 2943\n",
      "Number of female names: 5001\n"
     ]
    }
   ],
   "source": [
    "print \"Number of male names: {}\".format(len(maleNames))\n",
    "print \"Number of female names: {}\".format(len(femaleNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have to do our splits separately. We will split the data with the goal of maintaining the same ratio of male to female in our train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perMale = 1.0 * len(maleNames) / (len(maleNames) + len(femaleNames))\n",
    "perMale\n",
    "\n",
    "# total names\n",
    "numNames = len(names.words())\n",
    "# number used for testing\n",
    "numTesting = 1000\n",
    "# slit between final test and validation\n",
    "perTest = 0.5\n",
    "\n",
    "# numbers for data splitting\n",
    "numTestingMale = int(perMale * numTesting)\n",
    "numTestingFemale = numTesting - numTestingMale\n",
    "\n",
    "numTestMale = int(numTesting * perTest * perMale)\n",
    "numTestFemale = int(numTesting *  perTest - numTestMale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Set   = 500 (Should be 500)\n",
      "Test Set  = 500 (Should be 500)\n",
      "Train Set = 6944 (Should be >6900)\n"
     ]
    }
   ],
   "source": [
    "maleTrain, maleTesting = train_test_split(\n",
    "    maleNames, test_size=numTestingMale, random_state=5)\n",
    "maleVal, maleTest = train_test_split(\n",
    "    maleTesting, test_size=numTestMale, random_state=6)\n",
    "\n",
    "femaleTrain, femaleTesting = train_test_split(\n",
    "    femaleNames, test_size=numTestingFemale, random_state=7)\n",
    "femaleVal, femaleTest = train_test_split(\n",
    "    femaleTesting, test_size=numTestFemale, random_state=8)\n",
    "\n",
    "# Check numbers\n",
    "print \"Val Set   = {} (Should be 500)\".format(len(maleVal) + len(femaleVal))\n",
    "print \"Test Set  = {} (Should be 500)\".format(len(maleTest) + len(femaleTest))\n",
    "print \"Train Set = {} (Should be >6900)\".format(len(maleTrain) + len(femaleTrain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame({'name': maleTrain + femaleTrain,\n",
    "                      'sex': (['male'] * len(maleTrain) + \n",
    "                              ['female'] * len(femaleTrain))})\n",
    "validation = pd.DataFrame({'name': maleVal + femaleVal,\n",
    "                           'sex': (['male'] * len(maleVal) +\n",
    "                                   ['female'] * len(femaleVal))})\n",
    "test = pd.DataFrame({'name': maleTest + femaleTest,\n",
    "                     'sex': (['male'] * len(maleTest) +\n",
    "                             ['female'] * len(femaleTest))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name    Kristos\n",
      "sex        male\n",
      "Name: 56, dtype: object\n",
      "\n",
      "name    Orton\n",
      "sex      male\n",
      "Name: 38, dtype: object\n",
      "\n",
      "name      Shea\n",
      "sex     female\n",
      "Name: 486, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Just to make sure we all see the same thing\n",
    "print train.loc[56, :]\n",
    "print\n",
    "print validation.loc[38, :]\n",
    "print\n",
    "print test.loc[486, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names should be Kristos, Orton, and Shea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above code to start another notebook to explore an algorithm. Make sure to use the splits as defined above and to not use the final test set to tune your model. =-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some features ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addEdge(source, target):\n",
    "    G.add_edge(source, target)\n",
    "    try:       G.edge[source][target]['weight'] += 1\n",
    "    except KeyError:\n",
    "        G.edge[source][target]['weight'] = 1\n",
    "\n",
    "def addFeature(rowNum, description, feature):\n",
    "    ftext = description + \" \" + feature\n",
    "    G.add_node(ftext)\n",
    "    G.node[ftext]['label'] = 'feature'\n",
    "    addEdge(rowNum, ftext)\n",
    "\n",
    "def featuresFromName(rowNum, name, sex):\n",
    "    # We're going to use a bernoullli classifier, so all our features\n",
    "    # will be binary\n",
    "    G.add_node(rowNum)\n",
    "    G.node[rowNum]['label'] = 'name'\n",
    "    G.node[rowNum]['name'] = name\n",
    "    G.node[rowNum]['sex'] = sex\n",
    "    n = len(name)\n",
    "    \n",
    "    # first letter\n",
    "    addFeature(rowNum, \"1st letter\", name[0])\n",
    "    \n",
    "    # last letter\n",
    "    ll = \"last letter \" + name[-1]\n",
    "    addFeature(rowNum, \"last letter\", name[-1])\n",
    "    \n",
    "    # n-grams\n",
    "    for n_gram in [name[i:i+2] for i in range(n - 1)]:\n",
    "        addFeature(rowNum, \"containts\", n_gram)\n",
    "    \n",
    "    # length of names\n",
    "    addFeature(rowNum, \"length is\", str(n))\n",
    "    \n",
    "def returngen(nodeType):\n",
    "    # generator for nodes of type nodeType\n",
    "    return (n for n in G.nodes() if G.node[n]['label'] == nodeType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a small scale trial to make sure we're getting what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "[[0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      "  0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]]\n",
      "rows:\n",
      "barthel\n",
      "claudius\n",
      "aharon\n",
      "staffard\n",
      "jessey\n",
      "david\n",
      "selig\n",
      "hersh\n",
      "pietro\n",
      "adolf\n",
      "chet\n",
      "rollin\n",
      "columns:\n",
      "last letter d\n",
      "last letter s\n",
      "1st letter p\n",
      "last letter l\n",
      "containts ba\n",
      "last letter n\n",
      "containts da\n",
      "last letter h\n",
      "length is 8\n",
      "length is 7\n",
      "length is 6\n",
      "length is 5\n",
      "last letter f\n",
      "containts di\n",
      "last letter g\n",
      "containts fa\n",
      "containts pi\n",
      "containts iu\n",
      "containts ta\n",
      "containts ah\n",
      "containts rd\n",
      "containts af\n",
      "1st letter d\n",
      "containts on\n",
      "containts ro\n",
      "containts th\n",
      "last letter y\n",
      "containts rs\n",
      "containts ig\n",
      "containts id\n",
      "containts ie\n",
      "containts rt\n",
      "containts in\n",
      "containts st\n",
      "containts au\n",
      "containts ar\n",
      "containts do\n",
      "containts ll\n",
      "containts ff\n",
      "containts ey\n",
      "last letter t\n",
      "containts er\n",
      "containts es\n",
      "1st letter r\n",
      "1st letter s\n",
      "containts ad\n",
      "containts et\n",
      "1st letter h\n",
      "containts av\n",
      "1st letter j\n",
      "containts el\n",
      "containts tr\n",
      "containts ch\n",
      "1st letter a\n",
      "1st letter b\n",
      "1st letter c\n",
      "containts cl\n",
      "length is 4\n",
      "containts se\n",
      "containts sh\n",
      "last letter o\n",
      "containts ud\n",
      "containts ha\n",
      "containts ol\n",
      "containts ss\n",
      "containts he\n",
      "containts je\n",
      "containts us\n",
      "containts lf\n",
      "containts la\n",
      "containts li\n",
      "containts vi\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "for (i, nm, sx) in train.itertuples():\n",
    "    featuresFromName(i, nm.lower(), sx)\n",
    "    if i > 10:\n",
    "        break\n",
    "\n",
    "m = nx.bipartite.biadjacency_matrix(\n",
    "    G,\n",
    "    [n for n in G.nodes() if G.node[n]['label'] == 'name'],\n",
    "    [n for n in G.nodes() if G.node[n]['label'] == 'feature']\n",
    ").toarray()\n",
    "\n",
    "print type(m)\n",
    "print m\n",
    "\n",
    "print \"rows:\"\n",
    "for x in returngen('name'):\n",
    "    print G.node[x]['name']\n",
    "\n",
    "print \"columns:\"\n",
    "for x in returngen('feature'):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, now we see process the entire training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "for (i, nm, sx) in train.itertuples():\n",
    "    featuresFromName(i, nm.lower(), sx)\n",
    "\n",
    "X = nx.bipartite.biadjacency_matrix(\n",
    "    G,\n",
    "    [n for n in G.nodes() if G.node[n]['label'] == 'name'],\n",
    "    [n for n in G.nodes() if G.node[n]['label'] == 'feature']\n",
    ").toarray()\n",
    "\n",
    "# Now we need Y, the results column\n",
    "Y = []\n",
    "for x in returngen('name'):\n",
    "    Y.append(G.node[x]['sex'])\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Time to train our model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our validation set, we need to do things a little differently. First we need to extract our training feature set, then we need to apply that feature set to our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'containts vo',\n",
       " u'containts vi',\n",
       " u'containts ve',\n",
       " u'containts iv',\n",
       " u'containts iw',\n",
       " u'containts it',\n",
       " u'containts iu',\n",
       " u'containts ir',\n",
       " u'containts is',\n",
       " u'containts ip']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract our feature set\n",
    "featureSet = []\n",
    "for x in returngen('feature'):\n",
    "    featureSet.append(x)\n",
    "\n",
    "\n",
    "featureSet[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
