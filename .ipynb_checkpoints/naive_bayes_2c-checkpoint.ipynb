{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS620 Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Group project: Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev- test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= blue> <b>Group Members:- Aaron Palumbo, Brian Chu,  David Stern, Partha Banerjee;  Rohan Fray, Tulasi Ramarao;</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import networkx as nx\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/parallel.py:13: ShimWarning: The `IPython.parallel` package has been deprecated. You should import from ipyparallel instead.\n",
      "  \"You should import from ipyparallel instead.\", ShimWarning)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6f4732c313b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mqtid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mqtid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaunchConsole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mqtid\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturnPyIDs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6f4732c313b9>\u001b[0m in \u001b[0;36mlaunchConsole\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mafter_pyids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturnPyIDs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnewid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafter_pyids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore_pyids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %load qtutil.py\n",
    "# silly utility to launch a qtconsole if one doesn't exist\n",
    "import psutil\n",
    "\n",
    "def returnPyIDs():\n",
    "    pyids = set()\n",
    "    for pid in psutil.pids():\n",
    "        try:\n",
    "            if \"python\" in psutil.Process(pid).name():\n",
    "                pyids.add(pid)\n",
    "        except:\n",
    "            pass\n",
    "    return pyids\n",
    "\n",
    "def launchConsole():\n",
    "    before_pyids = returnPyIDs()\n",
    "    %qtconsole\n",
    "    after_pyids = returnPyIDs()\n",
    "    newid = after_pyids.difference(before_pyids)\n",
    "    assert len(newid) == 1\n",
    "    return list(newid)[0]\n",
    "\n",
    "try:\n",
    "    qtid\n",
    "except NameError:\n",
    "    qtid = launchConsole()\n",
    "    \n",
    "if qtid not in returnPyIDs():\n",
    "    qtid = launchConsole()\n",
    "    \n",
    "qtid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = nltk.corpus.names\n",
    "maleNames = names.words('male.txt')\n",
    "femaleNames = names.words('female.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training Data\n",
    "\n",
    "    * Train Set: Used to train the model\n",
    "\n",
    "    * Validation Set: Model Selection\n",
    "\n",
    "* Test Set: Measure Final Model performance (Only use this once at the end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different numbers of male and female names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of male names: 2943\n",
      "Number of female names: 5001\n"
     ]
    }
   ],
   "source": [
    "print \"Number of male names: {}\".format(len(maleNames))\n",
    "print \"Number of female names: {}\".format(len(femaleNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have to do our splits separately. We will split the data with the goal of maintaining the same ratio of male to female in our train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perMale = 1.0 * len(maleNames) / (len(maleNames) + len(femaleNames))\n",
    "perMale\n",
    "\n",
    "# total names\n",
    "numNames = len(names.words())\n",
    "# number used for testing\n",
    "numTesting = 1000\n",
    "# slit between final test and validation\n",
    "perTest = 0.5\n",
    "\n",
    "# numbers for data splitting\n",
    "numTestingMale = int(perMale * numTesting)\n",
    "numTestingFemale = numTesting - numTestingMale\n",
    "\n",
    "numTestMale = int(numTesting * perTest * perMale)\n",
    "numTestFemale = int(numTesting *  perTest - numTestMale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Set   = 500 (Should be 500)\n",
      "Test Set  = 500 (Should be 500)\n",
      "Train Set = 6944 (Should be >6900)\n"
     ]
    }
   ],
   "source": [
    "maleTrain, maleTesting = train_test_split(\n",
    "    maleNames, test_size=numTestingMale, random_state=5)\n",
    "maleVal, maleTest = train_test_split(\n",
    "    maleTesting, test_size=numTestMale, random_state=6)\n",
    "\n",
    "femaleTrain, femaleTesting = train_test_split(\n",
    "    femaleNames, test_size=numTestingFemale, random_state=7)\n",
    "femaleVal, femaleTest = train_test_split(\n",
    "    femaleTesting, test_size=numTestFemale, random_state=8)\n",
    "\n",
    "# Check numbers\n",
    "print \"Val Set   = {} (Should be 500)\".format(len(maleVal) + len(femaleVal))\n",
    "print \"Test Set  = {} (Should be 500)\".format(len(maleTest) + len(femaleTest))\n",
    "print \"Train Set = {} (Should be >6900)\".format(len(maleTrain) + len(femaleTrain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame({'name': maleTrain + femaleTrain,\n",
    "                      'sex': (['male'] * len(maleTrain) + \n",
    "                              ['female'] * len(femaleTrain))})\n",
    "validation = pd.DataFrame({'name': maleVal + femaleVal,\n",
    "                           'sex': (['male'] * len(maleVal) +\n",
    "                                   ['female'] * len(femaleVal))})\n",
    "test = pd.DataFrame({'name': maleTest + femaleTest,\n",
    "                     'sex': (['male'] * len(maleTest) +\n",
    "                             ['female'] * len(femaleTest))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name    Kristos\n",
      "sex        male\n",
      "Name: 56, dtype: object\n",
      "\n",
      "name    Orton\n",
      "sex      male\n",
      "Name: 38, dtype: object\n",
      "\n",
      "name      Shea\n",
      "sex     female\n",
      "Name: 486, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Just to make sure we all see the same thing\n",
    "print train.loc[56, :]\n",
    "print\n",
    "print validation.loc[38, :]\n",
    "print\n",
    "print test.loc[486, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names should be Kristos, Orton, and Shea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above code to start another notebook to explore an algorithm. Make sure to use the splits as defined above and to not use the final test set to tune your model. =-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some features ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addEdge(G, source, target):\n",
    "    G.add_edge(source, target)\n",
    "    try:\n",
    "        # this will fail if the edge is just created\n",
    "        G.edge[source][target]['weight'] += 1\n",
    "    except KeyError:\n",
    "        G.edge[source][target]['weight'] = 1\n",
    "\n",
    "def addFeature(G, rowNum, description, feature, trainingMode=True):\n",
    "    # create unique feature identifier\n",
    "    ftext = description + \" \" + feature\n",
    "    # if we're in training mode add the feature\n",
    "    # if we're not in training mode we only want link name\n",
    "    # to features that already exist\n",
    "    # note that the second part is not run unless trainingMode == False\n",
    "    if trainingMode or ftext in [f for f in returngen(G, 'feature')]:\n",
    "        G.add_node(ftext, label='feature')\n",
    "        addEdge(G, rowNum, ftext)\n",
    "\n",
    "def featuresFromName(G, rowNum, name, sex, options):\n",
    "    trainingMode = options['trainingMode']\n",
    "    # We're going to use a bernoullli classifier, so all our features\n",
    "    # will be binary\n",
    "    \n",
    "    # add the name node\n",
    "    G.add_node(rowNum, # using rowNum because name is not unique\n",
    "               label = 'name',\n",
    "               name = name,\n",
    "               sex = sex) \n",
    "    n = len(name)\n",
    "        \n",
    "    # first letter\n",
    "    if options['first_letter']:\n",
    "        addFeature(G, rowNum, \"1st letter\", name[0], trainingMode)\n",
    "    \n",
    "    # last letter\n",
    "    if options['last_letter']:\n",
    "        addFeature(G, rowNum, \"last letter\", name[-1], trainingMode)\n",
    "    \n",
    "    # two-grams\n",
    "    if options['two_grams']:\n",
    "        for n_gram in [name[i:i+2] for i in range(n - 1)]:\n",
    "            addFeature(G, rowNum, \"contains\", n_gram, trainingMode)\n",
    "    \n",
    "    # length of names\n",
    "    if options['length']:\n",
    "        addFeature(G, rowNum, \"length is\", str(n), trainingMode)\n",
    "    \n",
    "    # first two letters\n",
    "    if options['first_two']:\n",
    "        addFeature(G, rowNum, \"first two\", name[:2], trainingMode)\n",
    "    \n",
    "    # last two letters\n",
    "    if options['last_two']:\n",
    "        addFeature(G, rowNum, \"last_two\", name[-2:], trainingMode)\n",
    "        \n",
    "    # first four letters\n",
    "    if options['first_two']:\n",
    "        addFeature(G, rowNum, \"first_four\", name[0:3], trainingMode)\n",
    "    \n",
    "    # last three letters\n",
    "    if options['last_two']:\n",
    "        addFeature(G, rowNum, \"last_three\", name[-3:-1], trainingMode)\n",
    "    \n",
    "def returngen(G, nodeType):\n",
    "    # generator for nodes of type nodeType\n",
    "    return (n for n in G.nodes() if G.node[n]['label'] == nodeType)\n",
    "\n",
    "options = {'first_letter': True,\n",
    "           'last_letter':  True,\n",
    "           'two_grams':    True,\n",
    "           'length':       True,\n",
    "           'first_two':    True,\n",
    "           'last_two':     True,\n",
    "           'first_four':   True,\n",
    "           'last_three':   True}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a small scale trial to make sure we're getting what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "[[0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      "  1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0\n",
      "  0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
      "  0 0 0 1 0 1]]\n",
      "rows:\n",
      "    barthel\n",
      "    claudius\n",
      "    aharon\n",
      "    staffard\n",
      "    jessey\n",
      "    david\n",
      "    rollin\n",
      "columns:\n",
      "    last letter y\n",
      "    contains li\n",
      "    contains ll\n",
      "    last letter s\n",
      "    contains la\n",
      "    last letter l\n",
      "    last letter n\n",
      "    contains se\n",
      "    contains da\n",
      "    length is 7\n",
      "    last letter d\n",
      "    length is 5\n",
      "    contains di\n",
      "    contains ta\n",
      "    first two da\n",
      "    contains st\n",
      "    contains th\n",
      "    last_three vi\n",
      "    last_two us\n",
      "    first_four bar\n",
      "    contains es\n",
      "    contains ss\n",
      "    contains ey\n",
      "    first two st\n",
      "    1st letter r\n",
      "    1st letter s\n",
      "    1st letter j\n",
      "    1st letter a\n",
      "    1st letter b\n",
      "    1st letter c\n",
      "    1st letter d\n",
      "    contains el\n",
      "    last_two ey\n",
      "    first two cl\n",
      "    contains ud\n",
      "    contains us\n",
      "    last_three li\n",
      "    last_two el\n",
      "    contains ba\n",
      "    length is 8\n",
      "    length is 6\n",
      "    last_two rd\n",
      "    first_four dav\n",
      "    last_three iu\n",
      "    contains je\n",
      "    contains rt\n",
      "    first_four sta\n",
      "    last_three ar\n",
      "    contains rd\n",
      "    contains cl\n",
      "    contains ro\n",
      "    first_four jes\n",
      "    first_four cla\n",
      "    first two ah\n",
      "    last_three ro\n",
      "    contains ha\n",
      "    contains he\n",
      "    first_four aha\n",
      "    contains ah\n",
      "    contains au\n",
      "    contains av\n",
      "    contains ar\n",
      "    last_three he\n",
      "    contains iu\n",
      "    last_three se\n",
      "    last_two id\n",
      "    contains in\n",
      "    contains id\n",
      "    last_two in\n",
      "    first two ro\n",
      "    contains af\n",
      "    contains ff\n",
      "    contains fa\n",
      "    contains vi\n",
      "    last_two on\n",
      "    first two je\n",
      "    first two ba\n",
      "    first_four rol\n",
      "    contains on\n",
      "    contains ol\n"
     ]
    }
   ],
   "source": [
    "tg = nx.Graph()\n",
    "options['trainingMode'] = True\n",
    "for (i, nm, sx) in train.itertuples():\n",
    "    featuresFromName(tg, i, nm.lower(), sx, options)\n",
    "    if i > 5:\n",
    "        break\n",
    "\n",
    "m = nx.bipartite.biadjacency_matrix(\n",
    "    tg,\n",
    "    [n for n in tg.nodes() if tg.node[n]['label'] == 'name'],\n",
    "    [n for n in tg.nodes() if tg.node[n]['label'] == 'feature']\n",
    ").toarray()\n",
    "\n",
    "print type(m)\n",
    "print m\n",
    "\n",
    "print \"rows:\"\n",
    "for x in returngen(tg, 'name'):\n",
    "    print \"    {}\".format(tg.node[x]['name'])\n",
    "\n",
    "print \"columns:\"\n",
    "for x in returngen(tg, 'feature'):\n",
    "    print \"    {}\".format(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, now we see process the entire training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8597350230414746"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg = nx.Graph()\n",
    "options['trainingMode'] = True\n",
    "\n",
    "for (i, nm, sx) in train.itertuples():\n",
    "    featuresFromName(tg, i, nm.lower(), sx, options)\n",
    "\n",
    "X = nx.bipartite.biadjacency_matrix(\n",
    "    tg,\n",
    "    [n for n in returngen(tg, 'name')],\n",
    "    [n for n in returngen(tg, 'feature')]\n",
    ").toarray()\n",
    "\n",
    "# Now we need Y, the results column\n",
    "Y = []\n",
    "for x in returngen(tg, 'name'):\n",
    "    Y.append(tg.node[x]['sex'])\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Time to train our model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X, Y)\n",
    "\n",
    "Ytrain = bnb.predict(X)\n",
    "\n",
    "1.0 * sum(Y == Ytrain) / len(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our validation set, we need to do things a little differently. First we need to extract our training feature set, then we need to apply that feature set to our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.394"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract our feature set\n",
    "vg = nx.Graph()\n",
    "for x in returngen(tg, 'feature'):\n",
    "    vg.add_node(x, label='feature')\n",
    "\n",
    "options['trainingMode'] = False\n",
    "# Connect validation names to existing features\n",
    "for (i, nm, sx) in validation.itertuples():\n",
    "    featuresFromName(vg, i, nm.lower(), sx, options)\n",
    "\n",
    "Xval = nx.bipartite.biadjacency_matrix(\n",
    "    vg,\n",
    "    [n for n in returngen(vg, 'name')],\n",
    "    [n for n in returngen(vg, 'feature')]\n",
    ")\n",
    "\n",
    "Yval = []\n",
    "for x in returngen(vg, 'name'):\n",
    "    Yval.append(vg.node[x]['sex'])\n",
    "Yval = np.array(Yval)\n",
    "\n",
    "Ypredicted =  bnb.predict(Xval)\n",
    "\n",
    "1.0 * sum(Yval == Ypredicted) / len(Yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put this all together so we can run through different options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runNaiveBayes(train, validation, options):\n",
    "    tg = nx.Graph()\n",
    "    options['trainingMode'] = True\n",
    "\n",
    "    for (i, nm, sx) in train.itertuples():\n",
    "        featuresFromName(tg, i, nm.lower(), sx, options)\n",
    "\n",
    "    X = nx.bipartite.biadjacency_matrix(\n",
    "        tg,\n",
    "        [n for n in returngen(tg, 'name')],\n",
    "        [n for n in returngen(tg, 'feature')]\n",
    "    ).toarray()\n",
    "\n",
    "    # Now we need Y, the results column\n",
    "    Y = []\n",
    "    for x in returngen(tg, 'name'):\n",
    "        Y.append(tg.node[x]['sex'])\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    # Time to train our model\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(X, Y)\n",
    "\n",
    "    Ytrain = bnb.predict(X)\n",
    "\n",
    "    trainacc = 1.0 * sum(Y == Ytrain) / len(Y)\n",
    "    \n",
    "    # Extract our feature set\n",
    "    vg = nx.Graph()\n",
    "    for x in returngen(tg, 'feature'):\n",
    "        vg.add_node(x, label='feature')\n",
    "\n",
    "    options['trainingMode'] = False\n",
    "    # Connect validation names to existing features\n",
    "    for (i, nm, sx) in validation.itertuples():\n",
    "        featuresFromName(vg, i, nm.lower(), sx, options)\n",
    "\n",
    "    Xval = nx.bipartite.biadjacency_matrix(\n",
    "        vg,\n",
    "        [n for n in returngen(vg, 'name')],\n",
    "        [n for n in returngen(vg, 'feature')]\n",
    "    )\n",
    "\n",
    "    Yval = []\n",
    "    for x in returngen(vg, 'name'):\n",
    "        Yval.append(vg.node[x]['sex'])\n",
    "    Yval = np.array(Yval)\n",
    "\n",
    "    Ypredicted =  bnb.predict(Xval)\n",
    "\n",
    "    valacc = 1.0 * sum(Yval == Ypredicted) / len(Yval)\n",
    "    return trainacc, valacc\n",
    "\n",
    "def printResults(options, trainacc, valacc):\n",
    "    print \"The training accuracy was           {}\".format(round(trainacc, 3))\n",
    "    print \"and the the validation accuracy was {}\".format(round(valacc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.86\n",
      "and the the validation accuracy was 0.394\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': True,\n",
    "           'last_letter':  True,\n",
    "           'two_grams':    True,\n",
    "           'length':       True,\n",
    "           'first_two':    True,\n",
    "           'last_two':     True}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.649\n",
      "and the the validation accuracy was 0.666\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': True,\n",
    "           'last_letter':  False,\n",
    "           'two_grams':    False,\n",
    "           'length':       False,\n",
    "           'first_two':    False,\n",
    "           'last_two':     False}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.764\n",
      "and the the validation accuracy was 0.768\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': False,\n",
    "           'last_letter':  True,\n",
    "           'two_grams':    False,\n",
    "           'length':       False,\n",
    "           'first_two':    False,\n",
    "           'last_two':     False}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.765\n",
      "and the the validation accuracy was 0.41\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': False,\n",
    "           'last_letter':  False,\n",
    "           'two_grams':    True,\n",
    "           'length':       False,\n",
    "           'first_two':    False,\n",
    "           'last_two':     False}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.631\n",
      "and the the validation accuracy was 0.646\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': False,\n",
    "           'last_letter':  False,\n",
    "           'two_grams':    False,\n",
    "           'length':       True,\n",
    "           'first_two':    False,\n",
    "           'last_two':     False}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.777\n",
      "and the the validation accuracy was 0.524\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': False,\n",
    "           'last_letter':  False,\n",
    "           'two_grams':    False,\n",
    "           'length':       False,\n",
    "           'first_two':    True,\n",
    "           'last_two':     False}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.815\n",
      "and the the validation accuracy was 0.468\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': False,\n",
    "           'last_letter':  False,\n",
    "           'two_grams':    False,\n",
    "           'length':       False,\n",
    "           'first_two':    False,\n",
    "           'last_two':     True}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that seem to have to most predictive power are last letter, first letter, and length. Combining these features we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.781\n",
      "and the the validation accuracy was 0.73\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': True,\n",
    "           'last_letter':  True,\n",
    "           'two_grams':    False,\n",
    "           'length':       True,\n",
    "           'first_two':    False,\n",
    "           'last_two':     False}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.778\n",
      "and the the validation accuracy was 0.798\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': True,\n",
    "           'last_letter':  True,\n",
    "           'two_grams':    False,\n",
    "           'length':       False,\n",
    "           'first_two':    False,\n",
    "           'last_two':     False}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.652\n",
      "and the the validation accuracy was 0.474\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': True,\n",
    "           'last_letter':  False,\n",
    "           'two_grams':    False,\n",
    "           'length':       True,\n",
    "           'first_two':    False,\n",
    "           'last_two':     False}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.759\n",
      "and the the validation accuracy was 0.784\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': False,\n",
    "           'last_letter':  True,\n",
    "           'two_grams':    False,\n",
    "           'length':       True,\n",
    "           'first_two':    False,\n",
    "           'last_two':     False}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy was           0.778\n",
      "and the the validation accuracy was 0.798\n"
     ]
    }
   ],
   "source": [
    "options = {'first_letter': True,\n",
    "           'last_letter':  True,\n",
    "           'two_grams':    False,\n",
    "           'length':       False,\n",
    "           'first_four':   True,\n",
    "           'last_three':   True,\n",
    "           'first_two':    False,\n",
    "           'last_two':     False}\n",
    "\n",
    "ta, va = runNaiveBayes(train, validation, options)\n",
    "printResults(options, ta, va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results, it looks like using just first and last letter is the best choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
